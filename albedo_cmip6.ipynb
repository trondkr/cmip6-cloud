{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from albedo.ipynb\n",
      "importing Jupyter notebook from albedo_tools.ipynb\n",
      "importing Jupyter notebook from regrid_cmip6.ipynb\n",
      "importing Jupyter notebook from seasonal_average.ipynb\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "# Computational modules\n",
    "import dask\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "import datetime\n",
    "# Maps   \n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box, mapping\n",
    "import dateutil\n",
    "from cartopy.util import add_cyclic_point\n",
    "import import_ipynb\n",
    "import os\n",
    "\n",
    "# Local files and utility functions\n",
    "sys.path.append(\"./subroutines/\")\n",
    "import pices\n",
    "import tables\n",
    "import pytz\n",
    "import pvlib\n",
    "\n",
    "# Import other notebooks\n",
    "import albedo\n",
    "import albedo_tools\n",
    "import regrid_cmip6\n",
    "import seasonal_average\n",
    "\n",
    "import xesmf as xe\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 6\n",
    "get_ipython().run_line_magic(\"config\", \"InlineBackend.figure_format = 'retina'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43359</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/trondkr/proxy/8787/status' target='_blank'>/user/trondkr/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>63.33 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43359' processes=4 threads=16, memory=63.33 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Amon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='uas'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Amon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='uas'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Amon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='vas'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Amon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='vas'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Omon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='chl'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Omon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='chl'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Amon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='clt'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='Amon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='clt'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='sithick'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='sithick'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='siconc'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='siconc'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='sisnthick'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='sisnthick'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and grid_label=='gn' and experiment_id=='historical' and variable_id=='sisnconc'\n",
      "\n",
      "Time encoding: DatetimeIndex(['1850-01-16 12:00:00', '1850-02-15 00:00:00',\n",
      "               '1850-03-16 12:00:00', '1850-04-16 00:00:00',\n",
      "               '1850-05-16 12:00:00', '1850-06-16 00:00:00',\n",
      "               '1850-07-16 12:00:00', '1850-08-16 12:00:00',\n",
      "               '1850-09-16 00:00:00', '1850-10-16 12:00:00',\n",
      "               ...\n",
      "               '2014-03-16 12:00:00', '2014-04-16 00:00:00',\n",
      "               '2014-05-16 12:00:00', '2014-06-16 00:00:00',\n",
      "               '2014-07-16 12:00:00', '2014-08-16 12:00:00',\n",
      "               '2014-09-16 00:00:00', '2014-10-16 12:00:00',\n",
      "               '2014-11-16 00:00:00', '2014-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1980, freq=None) - datetime64[ns]\n",
      "Running projections query on data: \n",
      " ==> source_id=='ACCESS-ESM1-5'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gn' and experiment_id=='ssp585' and variable_id=='sisnconc'\n",
      "\n",
      "Time encoding: DatetimeIndex(['2015-01-16 12:00:00', '2015-02-15 00:00:00',\n",
      "               '2015-03-16 12:00:00', '2015-04-16 00:00:00',\n",
      "               '2015-05-16 12:00:00', '2015-06-16 00:00:00',\n",
      "               '2015-07-16 12:00:00', '2015-08-16 12:00:00',\n",
      "               '2015-09-16 00:00:00', '2015-10-16 12:00:00',\n",
      "               ...\n",
      "               '2100-03-16 12:00:00', '2100-04-16 00:00:00',\n",
      "               '2100-05-16 12:00:00', '2100-06-16 00:00:00',\n",
      "               '2100-07-16 12:00:00', '2100-08-16 12:00:00',\n",
      "               '2100-09-16 00:00:00', '2100-10-16 12:00:00',\n",
      "               '2100-11-16 00:00:00', '2100-12-16 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1032, freq=None) - datetime64[ns]\n",
      "ACCESS-ESM1-5 => Dates extracted range from 1950-01-16T12:00:00.000000000 to 2099-12-16T12:00:00.000000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Config_pices():\n",
    "    df = pd.read_csv(\"https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv\")\n",
    "    fs = gcsfs.GCSFileSystem(token=\"anon\", access=\"read_only\")\n",
    "    grid_labels = [\"gn\"]  # Can be gr=grid rotated, or gn=grid native\n",
    "    member_ids = [\"r1i1p1f1\"]  #\n",
    "    experiment_ids = [\"ssp585\"]  #'abrupt-4xCO2',\n",
    "    source_ids = [\"ACCESS-ESM1-5\"] #\"CanESM5\"] #\"MPI-ESM1-2-LR\"]\n",
    "    variable_ids = [\"uas\",\"vas\",\"chl\",\"clt\",\"sithick\", \"siconc\", \"sisnthick\", \"sisnconc\"]\n",
    "    table_ids = [\"Amon\",\"Amon\",\"Omon\",\"Amon\",\"SImon\",\"SImon\",\"SImon\",\"SImon\"]  # Amon=atmospheric variables, Omon=Ocean variables, SImon=sea-ice variables\n",
    "    dset_dict = {}\n",
    "    start_date=\"1950-01-01\"\n",
    "    end_date=\"2100-01-01\"\n",
    "    clim_start=\"1961-01-01\"\n",
    "    clim_end=\"1990-01-01\"\n",
    "    selected_depth=0\n",
    "  \n",
    "# Create the object\n",
    "config_pices_obj = Config_pices()\n",
    "config_pices_obj = pices.get_and_organize_cmip6_data(config_pices_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Roland Seferian, equation 3\n",
    "# https://www.geosci-model-dev.net/11/321/2018/gmd-11-321-2018.pdf\n",
    "\n",
    "def calculate_alpha_dir(n_lambda,µ):\n",
    "    a = np.sqrt(1.0 - (1.0 - µ**2)/n_lambda**2)\n",
    "    b = ((a-n_lambda*µ)/(a+n_lambda*µ))**2    \n",
    "    c = ((µ-n_lambda*a)/(µ+n_lambda*a))**2\n",
    "\n",
    "    return 0.5*(b+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diffuse_reflection(n_λ,σ):\n",
    "    # Diffuse albedo from Jin et al., 2006 (Eq 5b) \n",
    "    return -0.1479 + 0.1502*n_λ-0.0176*n_λ*σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_roughness(µ, σ):\n",
    "    # Surface roughness following Jin et al. 2014 equation 4\n",
    "    # This rougness parameter determines the Fresnel refraction \n",
    "    # index from flat surface\n",
    "    return (0.0152-1.7873*µ + 6.8972*(µ**2)-8.5778*(µ**3)+ 4.071*σ-7.6446*µ*σ) * np.exp(0.1643-7.8409*µ-3.5639*µ**2-2.3588*σ+10.054*µ*σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_direct_reflection(n_λ,µ,σ):\n",
    "    # Direct reflection following Jin et al. 2014 equation 1\n",
    "    f_0 = calculate_alpha_dir(1.34,µ)\n",
    "    f_λ = calculate_alpha_dir(n_λ,µ)\n",
    "    \n",
    "    return f_λ-(surface_roughness(µ, σ)*f_λ/f_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_direct_reflection_from_chl(λ, chl, alpha_chl, alpha_w, beta_w, σ, µ, alpha_direct):\n",
    "   \n",
    "    rw=0.48168549-0.014894708*σ-0.20703885*σ**2\n",
    " \n",
    "    # Determine absorption and backscattering\n",
    "    # coefficients to determine reflectance below the surface (Ro) once for all\n",
    "    # Backscattering by chlorophyll:\n",
    "    a_bp = 0.06*alpha_chl*np.exp(np.log(chl)*0.65) + 0.2*(0.00635+0.06*(np.exp(np.log(chl)*0.65))*np.exp(0.014*(440.0-λ)))\n",
    "   \n",
    "    # Backscattering of biological pigment (b_chl) with λ expressed here in nm and [Chl] in mg m−3. This\n",
    "    # formulation is valid for [Chl] ranging between 0.02 and 2 mg m−3 (Morel and Maritorena (2001))\n",
    "    # Equation 12 Roland Seferian, 2018\n",
    "    b_chl=(0.416*np.exp(0.766*np.log(chl)))*(0.002+0.01*(0.5-0.25*np.log(chl))*np.exp((0.5*(np.log(chl)-0.3))*np.log(λ/550.0)))\n",
    "                                                                                 \n",
    "    # # Use Morel 91 formula to compute the direct reflectance below the surface (Morel-Gentili(1991), Eq (12))\n",
    "    n=0.5*beta_w/(0.5*beta_w + b_chl)\n",
    "   \n",
    "    # Equation 11 Roland Seferian, 2018\n",
    "    beta = 0.6279-0.2227*n-0.0513*n**2 +(0.2465*n - 0.3119)*µ\n",
    "    \n",
    "    # Equation 10 Roland Seferian, 2018\n",
    "    R0 = beta * (0.5*beta_w + b_chl)/(alpha_w + a_bp)\n",
    "   \n",
    "    # Water leaving albedo, equation 8 Roland Seferian, 2018\n",
    "    return (R0*(1.0-rw)/(1-rw*R0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diffuse_reflection_from_chl(λ, chl, alpha_chl, alpha_w, beta_w, σ, alpha_direct):\n",
    "    #  In the case of ocean interior reflectance for direct incoming radiation it depends on µ = cos(θ) whereas in the\n",
    "    # case of ocean interior reflectance for diffuse µ = 0.676. This value is considered an effective angle of incoming radiation of 47.47◦\n",
    "    # according to Morel and Gentili (1991). Hence\n",
    "    return calculate_direct_reflection_from_chl(λ, chl, alpha_chl, alpha_w, beta_w, σ, np.arccos(0.676), alpha_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitecap(wind):\n",
    "    # Whitecap effect as defined by Salisbury et al. 2014. NOTE that the value in paper is in percent\n",
    "    # so we use the ratio instead (/100.) \n",
    "    # Salisbury, D. J., Anguelova, M. D., and Brooks, I. M.: Global Distribution and Seasonal \n",
    "    # Dependence of Satellite-based Whitecap Fraction\n",
    "    #\n",
    "    # Whitecaps are the surface manifestation of bubble plumes, created when \n",
    "    # surface gravity waves break and entrain air into the water column. \n",
    "    # They enhance air-sea exchange, introducing physical processes different from \n",
    "    # those operating at the bubble-free water surface. \n",
    "  \n",
    "    return 0.000397*(np.exp(1.59*np.log(wind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spectral_and_broadband_OSA(wind,alpha_wc,alpha_direct,alpha_diffuse,alpha_direct_chl,alpha_diffuse_chl,solar_energy):\n",
    "    wc = whitecap(wind)\n",
    "    OSA=np.zeros((1,2))\n",
    "    OSA_direct = (alpha_direct + alpha_direct_chl) * (1-wc) + wc*alpha_wc\n",
    "    OSA_diffuse = (alpha_diffuse + alpha_diffuse_chl) * (1-wc) + wc*alpha_wc\n",
    "    \n",
    "    # Integrate across all wavelengths 200-4000nm at 10 nm wavelength bands and then weight by the solar energy at each band.\n",
    "    # The solar energy is dimensionless with sum equal to 1 and therefore already weighted.\n",
    "    OSA_direct_broadband = np.sum(OSA_direct*solar_energy)\n",
    "    OSA_diffuse_broadband = np.sum(OSA_diffuse*solar_energy)\n",
    "    \n",
    "    OSA[0,0]=OSA_direct_broadband\n",
    "    OSA[0,1]=OSA_diffuse_broadband\n",
    "    return OSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OSA(µ_deg, uv, chl, wavelengths, refractive_indexes, alpha_chl, alpha_w, beta_w, alpha_wc, solar_energy):\n",
    "    \n",
    "    if (µ_deg<0 or µ_deg>180):\n",
    "        µ_deg=0\n",
    " \n",
    "    µ = np.cos(np.radians(µ_deg))\n",
    "    \n",
    "    # Solar zenith angle\n",
    "    # wind is wind at 10 m height (m/s)\n",
    "    σ = np.sqrt(0.003+0.00512*uv)\n",
    "         \n",
    "    # Vectorize the functions\n",
    "    vec_calculate_direct_reflection=np.vectorize(calculate_direct_reflection)\n",
    "    vec_calculate_diffuse_reflection=np.vectorize(calculate_diffuse_reflection)\n",
    "    vec_calculate_direct_reflection_from_chl=np.vectorize(calculate_direct_reflection_from_chl)\n",
    "    vec_calculate_diffuse_reflection_from_chl=np.vectorize(calculate_diffuse_reflection_from_chl)\n",
    "    \n",
    "    # Direct reflection\n",
    "    alpha_direct = vec_calculate_direct_reflection(refractive_indexes,µ,σ)\n",
    "   \n",
    "    # Diffuse reflection\n",
    "    alpha_diffuse = vec_calculate_diffuse_reflection(refractive_indexes,σ)\n",
    "\n",
    "    # Reflection from chlorophyll and biological pigments\n",
    "    alpha_direct_chl = vec_calculate_direct_reflection_from_chl(wavelengths, chl, alpha_chl, alpha_w, beta_w, σ, µ, alpha_direct)\n",
    "   \n",
    "    # Diffuse reflection interior of water from chlorophyll\n",
    "    alpha_diffuse_chl = vec_calculate_diffuse_reflection_from_chl(wavelengths, chl, alpha_chl, alpha_w, beta_w, σ, alpha_direct)\n",
    "\n",
    "    # OSA\n",
    "    return calculate_spectral_and_broadband_OSA(uv,alpha_wc,alpha_direct,alpha_diffuse,alpha_direct_chl,alpha_diffuse_chl,solar_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_parameters():\n",
    "    df=pd.read_csv(\"data/Wavelength/Fresnels_refraction.csv\", header=0, sep=\";\", decimal=\",\")\n",
    "    wavelengths=df[\"λ\"].values\n",
    "    refractive_indexes=df[\"n(λ)\"].values\n",
    "    alpha_chl=df[\"a_chl(λ)\"].values\n",
    "    alpha_w=df[\"a_w(λ)\"].values\n",
    "    beta_w=df[\"b_w(λ)\"].values\n",
    "    alpha_wc=df[\"a_wc(λ)\"].values\n",
    "    solar_energy=df[\"E(λ)\"].values\n",
    "    print(df.head())\n",
    "    return wavelengths, refractive_indexes, alpha_chl, alpha_w, beta_w, alpha_wc, solar_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiation calculations\n",
    "To calculate the irradiance at any given location on the planet at the exact same time of day we use the excellent [pvlib](https://github.com/pvlib/pvlib-python) Python library. This library allows us to calculate the direct and diffuse irradiance at the surface. The diffuse and direct (beam) irradiance are both corrected for cloud cover by applying the Liu Jordan equation. The approach is to sequentially calculate the following for each latitude in our grid, but for a fixed longitude position (lon=0) assuming that the solar daily cycle only varies with latitutde and time of day. The cloud cover is accounted for by first calculating the clear sky radiation and then scaling for cloud cover using the Liu Jordan equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiation(cloud_covers,latitude,month,hour_of_day):\n",
    "    results=np.zeros((np.shape(cloud_covers)[0],3))\n",
    "    #lon_180 = np.where(longitude > 180, longitude-360, longitude)\n",
    "    offset=0 #int(lon_180/15.)\n",
    "    when =[datetime.datetime(2006,month,15,hour_of_day,0,0,tzinfo=datetime.timezone(datetime.timedelta(hours=offset)))]\n",
    "    time = pd.DatetimeIndex(when)\n",
    "    sandia_modules = pvlib.pvsystem.retrieve_sam('SandiaMod')\n",
    "    sapm_inverters = pvlib.pvsystem.retrieve_sam('cecinverter')\n",
    "\n",
    "    module = sandia_modules['Canadian_Solar_CS5P_220M___2009_']\n",
    "    inverter = sapm_inverters['ABB__MICRO_0_25_I_OUTD_US_208__208V_']\n",
    "    system = {'module': module, 'inverter': inverter,\n",
    "                  'surface_azimuth': 180}\n",
    "    altitude=0.0\n",
    "    system['surface_tilt'] = latitude\n",
    "        \n",
    "    \n",
    "    # Some calculations are done only on greenwhich meridian line as they are identical around the globe \n",
    "    # at the same latitude. For that reason longitude is set to greenwhich meridian and do not change. The only reason \n",
    "    # to use longitude would be to have the local sun position for given time but since we calculate position at the same\n",
    "    # time of the day (hour_of_day) and month (month) we can assume its the same across all longitudes,\n",
    "    # and only change with latitude.\n",
    "    \n",
    "    longitude=0.0\n",
    "    solpos = pvlib.solarposition.get_solarposition(time, latitude, longitude)\n",
    "\n",
    "    dni_extra = pvlib.irradiance.get_extra_radiation(time)\n",
    "    airmass = pvlib.atmosphere.get_relative_airmass(solpos['apparent_zenith'])\n",
    "\n",
    "    pressure = pvlib.atmosphere.alt2pres(altitude)\n",
    "    am_abs = pvlib.atmosphere.get_absolute_airmass(airmass, pressure)\n",
    "    tl = pvlib.clearsky.lookup_linke_turbidity(time,latitude,longitude)\n",
    "\n",
    "    for cloud_index,cloud_cover in enumerate(cloud_covers):\n",
    "        \n",
    "        # cloud cover in percentage units here\n",
    "        transmittance = ((100.0 - cloud_cover) / 100.0) * 0.75\n",
    "        # irrads is a DataFrame containing ghi, dni, dhi\n",
    "        irrads = pvlib.irradiance.liujordan(solpos['apparent_zenith'], transmittance, am_abs)\n",
    "\n",
    "        aoi = pvlib.irradiance.aoi(system['surface_tilt'], system['surface_azimuth'],\n",
    "                                   solpos['apparent_zenith'], solpos['azimuth'])\n",
    "\n",
    "        total_irrad = pvlib.irradiance.get_total_irradiance(system['surface_tilt'],\n",
    "                                                            system['surface_azimuth'],\n",
    "                                                            solpos['apparent_zenith'],\n",
    "                                                            solpos['azimuth'],\n",
    "                                                            irrads['dni'], irrads['ghi'], irrads['dhi'],\n",
    "                                                            dni_extra=dni_extra,\n",
    "                                                            model='haydavies')\n",
    "\n",
    "\n",
    "       # effective_irradiance = pvlib.pvsystem.sapm_effective_irradiance(\n",
    "       #    total_irrad['poa_direct'], total_irrad['poa_diffuse'],\n",
    "       #    am_abs, aoi, module)\n",
    "       # print(\"({},{}) total {} direct: {} diffuse: {}\".format(latitude,longitude,total_irrad['poa_direct'][0]+total_irrad['poa_diffuse'][0],\n",
    "       #                                                total_irrad['poa_direct'][0], \n",
    "       #                                                total_irrad['poa_diffuse'][0]))\n",
    "       \n",
    "        results[cloud_index,0]=total_irrad['poa_direct']\n",
    "        results[cloud_index,1]=total_irrad['poa_diffuse']\n",
    "        results[cloud_index,2]=solpos['zenith']\n",
    "       \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_streamplot(indata_u,indata_v,uv, lon,lat,name,nlevels=None):\n",
    "    # Make data cyclic around dateline\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    crs_latlon = ccrs.PlateCarree()\n",
    "    \n",
    "    indata_u_cyclic, lon_cyclic = add_cyclic_point(indata_u, coord=lon)\n",
    "    indata_v_cyclic, lon_cyclic = add_cyclic_point(indata_v, coord=lon)\n",
    "    \n",
    "    cf = ax.contourf(lon_cyclic, lat, uv, 10,\n",
    "                 cmap='RdYlBu_r',\n",
    "                 extend='both',\n",
    "                 transform=ccrs.PlateCarree())\n",
    "    \n",
    "    land_110m = cfeature.NaturalEarthFeature('physical', 'land', '110m')  \n",
    "    sp = ax.streamplot(lon_cyclic, lat, indata_u_cyclic, indata_v_cyclic,\n",
    "                   linewidth=0.5,\n",
    "                   arrowsize = 0.4,\n",
    "                   density=10,\n",
    "                   color='k',\n",
    "                   transform=ccrs.PlateCarree())\n",
    "\n",
    "    cb = plt.colorbar(cf,orientation='horizontal', pad=0.04, aspect=50)\n",
    "    cb.ax.set_title('Wind speed [m/s]')\n",
    "    ax.add_feature(land_110m, color=\"lightgrey\")\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor=\"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(indata,lon,lat,name,nlevels=None,regional=False,logscale=False):\n",
    "    \n",
    "    proj=ccrs.PlateCarree()\n",
    "    proj=ccrs.NorthPolarStereo(true_scale_latitude=70)\n",
    "    ax = plt.axes(projection=proj)\n",
    "    land_10m = cfeature.NaturalEarthFeature('physical', 'land', '10m')\n",
    "    ax.add_feature(land_10m, color=\"lightgrey\", edgecolor=\"black\")\n",
    "  #  if regional:\n",
    "  #      land_10m = cfeature.NaturalEarthFeature('physical', 'land', '10m')\n",
    "  #      ax.add_feature(land_10m, color=\"lightgrey\", edgecolor=\"black\")\n",
    "  #      ax.set_extent([-180, 180, 45, 90])\n",
    "    \n",
    "    #indata_cyclic=indata\n",
    "    #lon_cyclic = lon \n",
    "    indata_cyclic, lon = add_cyclic_point(indata,coord=lon)\n",
    "    if nlevels is None:\n",
    "        if logscale:\n",
    "            from matplotlib import ticker, cm\n",
    "            cs=ax.contourf(lon,lat,indata_cyclic,10,\n",
    "                           transform=ccrs.PlateCarree(),\n",
    "                           cmap='RdYlBu_r',locator=ticker.LogLocator(subs=range(1,5)),extend='both')\n",
    "        else:\n",
    "            cs=ax.contourf(lon,lat,indata_cyclic,20,transform=ccrs.PlateCarree(),cmap='RdYlBu_r',extend='both')\n",
    "    else:\n",
    "        cs=ax.contourf(lon,lat,indata_cyclic,nlevels,transform=ccrs.PlateCarree(),cmap='RdYlBu_r',extend='both')\n",
    "    plt.title(\"{}\".format(name))\n",
    "    \n",
    " #   if regional:\n",
    " #       land_10m = cfeature.NaturalEarthFeature('physical', 'land', '10m')\n",
    " #       ax.add_feature(land_10m, color=\"lightgrey\", edgecolor=\"black\")\n",
    " #       ax.set_extent([-180, 180, 45, 90])\n",
    " #   else:\n",
    " #       land_110m = cfeature.NaturalEarthFeature('physical', 'land', '110m')\n",
    " #       ax.add_feature(land_110m, color=\"lightgrey\", edgecolor=\"black\")\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "        \n",
    "    plt.colorbar(cs,shrink=0.5)\n",
    "    plt.show()\n",
    "    if not os.path.exists(\"Figures\"): \n",
    "        os.mkdir(\"Figures\")\n",
    "    plotfilename=\"{}_anomaly_2050_2020.png\".format(name)\n",
    " #   plt.savefig(plotfilename, dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chlorophyll_avg_for_year(year,ds_in,ds_out):\n",
    "    start_date='{}-01-01'.format(year)\n",
    "    end_date='{}-12-31'.format(year)\n",
    "    ds_chl_2020=ds_in.sel(time=slice(start_date, end_date)) #.mean('time')\n",
    "    \n",
    "    year2=2050\n",
    "    start_date='{}-01-01'.format(year2)\n",
    "    end_date='{}-12-31'.format(year2)\n",
    "    ds_chl_2050=ds_in.sel(time=slice(start_date, end_date)) \n",
    "    \n",
    "    chl2020=regrid_cmip6.regrid_variable(\"chl\",ds_chl_2020,ds_out,transpose=False) \n",
    "    chl2050=regrid_cmip6.regrid_variable(\"chl\",ds_chl_2050,ds_out,transpose=False) \n",
    "    \n",
    "    ds_2020=chl2020.to_dataset()\n",
    "    ds_2050=chl2050.to_dataset()\n",
    "       \n",
    "    lat=ds_2020.lat.values\n",
    "    lon=ds_2020.lon.values\n",
    "        \n",
    "    weighted_average_2020 = season_mean(ds_2020,calendar=\"noleap\")\n",
    "    weighted_average_2050 = season_mean(ds_2050,calendar=\"noleap\")\n",
    "    \n",
    "    ds_diff =100*(weighted_average_2050 - weighted_average_2020)/weighted_average_2020\n",
    "    chl2020=(weighted_average_2020.sel(season=\"MAM\").chl.values)\n",
    "    chl2050=(weighted_average_2050.sel(season=\"MAM\").chl.values)\n",
    "    chl2050_diff=ds_diff.sel(season=\"MAM\").chl.values\n",
    "    \n",
    "    # kg/m3 to mg/m3 multiply by 1e6\n",
    "    create_plot((chl2020*1.e6),lon[0,:],lat[:,0],\"chl2020\",nlevels=np.arange(0,5,0.2),regional=True,logscale=True)\n",
    "    create_plot((chl2050*1.e6),lon[0,:],lat[:,0],\"chl2050\",nlevels=np.arange(0,5,0.2),regional=True,logscale=True)\n",
    "    create_plot((chl2050_diff),lon[0,:],lat[:,0],\"chl2050-2020\",nlevels=np.arange(-101,101,1), regional=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_mean(ds, calendar='standard'):\n",
    "    # Make a DataArray of season/year groups\n",
    "    \n",
    "    year_season = xr.DataArray(ds.time.to_index().to_period(freq='Q-NOV').to_timestamp(how='E'),\n",
    "                               coords=[ds.time], name='year_season')\n",
    "\n",
    "    # Make a DataArray with the number of days in each month, size = len(time)\n",
    "    month_length = xr.DataArray(albedo_tools.get_dpm(ds.time.to_index(), calendar=calendar),\n",
    "                                coords=[ds.time], name='month_length')\n",
    "    # Calculate the weights by grouping by 'time.season'\n",
    "    weights = month_length.groupby('time.season') / month_length.groupby('time.season').sum()\n",
    "\n",
    "    # Test that the sum of the weights for each season is 1.0\n",
    "    np.testing.assert_allclose(weights.groupby('time.season').sum().values, np.ones(4))\n",
    "\n",
    "    # Calculate the weighted average\n",
    "    return ((ds * weights).groupby('time.season').sum(dim='time'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_variable(varname,ds_in,ds_out,transpose=True):\n",
    "    regridder = xe.Regridder(ds_in, ds_out, 'bilinear', reuse_weights=True, periodic=True, ignore_degenerate=False)\n",
    "    #regridder.clean_weight_file()\n",
    "    \n",
    "    regridder._grid_in = None\n",
    "    regridder._grid_out = None\n",
    "\n",
    "    if transpose:\n",
    "        return regridder(ds_in[varname].T)\n",
    "    else:\n",
    "        return regridder(ds_in[varname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(sisnconc,sisnthick,sithick,siconc,clt,chl,rads,irradiance_water,wind,OSA,lon,lat):\n",
    "    # create_streamplot(dr_out_uas,dr_out_vas,wind,lon[0,:],lat[:,0],\"wind\",nlevels=None)\n",
    "    create_plot(wind,lon[0,:],lat[:,0],\"wind\",regional=True)\n",
    "    create_plot(sisnconc,lon[0,:],lat[:,0],\"sisnconc\",regional=True)\n",
    "    create_plot(sisnthick,lon[0,:],lat[:,0],\"sisnthick\",regional=True)\n",
    "    create_plot(siconc,lon[0,:],lat[:,0],\"siconc\",regional=True)\n",
    "    create_plot(sithick,lon[0,:],lat[:,0],\"sithick\",regional=True)\n",
    "    create_plot(clt,lon[0,:],lat[:,0],\"clouds\",regional=True)\n",
    "    create_plot(np.log(chl),lon[0,:],lat[:,0],\"chl (np.lon)\",regional=True)\n",
    "    create_plot(OSA[:,:,0],lon[0,:],lat[:,0],\"OSA_direct_broadband\",np.arange(0.01,0.04,0.001),regional=True)\n",
    "    create_plot(OSA[:,:,1],lon[0,:],lat[:,0],\"OSA_diffuse_broadband\",regional=True)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       λ      E(λ)  n(λ)  a_chl(λ)  a_w(λ)  b_w(λ)  a_wc(λ)\n",
      "0  200.0  0.000054  1.45     0.775   3.070  0.1510      0.0\n",
      "1  210.0  0.000206  1.44     0.752   1.990  0.1190      0.0\n",
      "2  220.0  0.000349  1.42     0.730   1.310  0.0995      0.0\n",
      "3  230.0  0.000384  1.41     0.708   0.928  0.0820      0.0\n",
      "4  240.0  0.000292  1.40     0.685   0.718  0.0685      0.0\n",
      "=> model: uas_ssp585_gn_ACCESS-ESM1-5_r1i1p1f1 variable name: uas\n",
      "=> model: vas_ssp585_gn_ACCESS-ESM1-5_r1i1p1f1 variable name: vas\n",
      "Reuse existing file: bilinear_192x37_23x180_peri.nc\n",
      "Reuse existing file: bilinear_23x180_45x360_peri.nc\n",
      "Reuse existing file: bilinear_192x36_23x180_peri.nc\n",
      "Reuse existing file: bilinear_23x180_45x360_peri.nc\n",
      "Reuse existing file: bilinear_192x37_23x180_peri.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n",
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n",
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse existing file: bilinear_23x180_45x360_peri.nc\n",
      "Reuse existing file: bilinear_87x360_45x360_peri.nc\n",
      "Reuse existing file: bilinear_87x360_45x360_peri.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n",
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n",
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n",
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n",
      "/opt/conda/lib/python3.7/site-packages/xesmf/backend.py:36: UserWarning: Input array is not F_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not F_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse existing file: bilinear_87x360_45x360_peri.nc\n",
      "Reuse existing file: bilinear_87x360_45x360_peri.nc\n",
      "Reuse existing file: bilinear_87x360_45x360_peri.nc\n",
      "Running for hour 12\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def calculate_light(config_pices_obj):\n",
    "      \n",
    "    selected_time=0\n",
    "    wavelengths, refractive_indexes, alpha_chl, alpha_w, beta_w, alpha_wc, solar_energy = albedo.setup_parameters()\n",
    "    startdate=datetime.datetime.now()\n",
    "    \n",
    "    regional=True\n",
    "   \n",
    "    southern_limit_latitude=45\n",
    "    for key in config_pices_obj.dset_dict.keys():\n",
    "        \n",
    "        var_name = key.split(\"_\")[0]\n",
    "        model_name = key.split(\"_\")[3]\n",
    "        \n",
    "        if var_name==\"uas\":\n",
    "            \n",
    "            key_v=\"vas\"+key[3:]\n",
    "            key_chl=\"chl\"+key[3:]\n",
    "            key_clt=\"clt\"+key[3:]\n",
    "            key_sisnconc=\"sisnconc\"+key[3:]\n",
    "            key_sisnthick=\"sisnthick\"+key[3:]\n",
    "            key_siconc=\"siconc\"+key[3:]\n",
    "            key_sithick=\"sithick\"+key[3:]\n",
    "            \n",
    "            var_name_v = key_v.split(\"_\")[0]\n",
    "            model_name_v = key_v.split(\"_\")[3]\n",
    "            \n",
    "            print(\"=> model: {} variable name: {}\".format(key, var_name))\n",
    "            print(\"=> model: {} variable name: {}\".format(key_v, var_name_v))\n",
    "          \n",
    "            if model_name_v==model_name:\n",
    "                \n",
    "                ds_uas=config_pices_obj.dset_dict[key].isel(time=selected_time) \n",
    "                ds_vas=config_pices_obj.dset_dict[key_v].isel(time=selected_time)\n",
    "                ds_chl=config_pices_obj.dset_dict[key_chl].isel(time=selected_time)\n",
    "                ds_clt=config_pices_obj.dset_dict[key_clt].isel(time=selected_time)\n",
    "                ds_sisnconc=config_pices_obj.dset_dict[key_sisnconc].isel(time=selected_time)\n",
    "                ds_sisnthick=config_pices_obj.dset_dict[key_sisnthick].isel(time=selected_time)\n",
    "                ds_siconc=config_pices_obj.dset_dict[key_siconc].isel(time=selected_time)\n",
    "                ds_sithick=config_pices_obj.dset_dict[key_sithick].isel(time=selected_time)\n",
    "                \n",
    "                if regional:\n",
    "                    ds_uas=ds_uas.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_vas=ds_vas.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_chl=ds_chl.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_clt=ds_clt.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_sisnconc=ds_sisnconc.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_sisnthick=ds_sisnthick.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_siconc=ds_siconc.sel(y=slice(southern_limit_latitude,90))\n",
    "                    ds_sithick=ds_sithick.sel(y=slice(southern_limit_latitude,90))\n",
    "                \n",
    "                # Regrid to cartesian grid:\n",
    "                # For any Amon related variables (wind, clouds), the resolution from CMIP6 models is less than \n",
    "                # 1 degree longitude x latitude. To interpolate to a 1x1 degree grid we therefore first interpolate to a \n",
    "                # 2x2 degrees grid and then subsequently to a 1x1 degree grid.\n",
    "                \n",
    "                ds_out_amon = xe.util.grid_2d(-180,180,2,southern_limit_latitude,90,2) \n",
    "                ds_out = xe.util.grid_2d(-180,180,1,southern_limit_latitude,90,1) #grid_global(1, 1)\n",
    "                \n",
    "                dr_out_uas_amon=regrid_variable(\"uas\",ds_uas,ds_out_amon,transpose=True).to_dataset()\n",
    "                dr_out_uas=regrid_variable(\"uas\",dr_out_uas_amon,ds_out,transpose=False)\n",
    "                \n",
    "                dr_out_vas_amon=regrid_variable(\"vas\",ds_vas,ds_out_amon,transpose=True).to_dataset()\n",
    "                dr_out_vas=regrid_variable(\"vas\",dr_out_vas_amon,ds_out,transpose=False)\n",
    "                \n",
    "                dr_out_clt_amon=regrid_variable(\"clt\",ds_clt,ds_out_amon,transpose=True).to_dataset()\n",
    "                dr_out_clt=regrid_variable(\"clt\",dr_out_clt_amon,ds_out,transpose=False)\n",
    "                dr_out_chl=regrid_variable(\"chl\",ds_chl,ds_out,transpose=False)\n",
    "                \n",
    "                dr_out_sisnconc=regrid_variable(\"sisnconc\",ds_sisnconc,ds_out,transpose=False)\n",
    "                dr_out_sisnthick=regrid_variable(\"sisnthick\",ds_sisnthick,ds_out,transpose=False)\n",
    "                dr_out_siconc=regrid_variable(\"siconc\",ds_siconc,ds_out,transpose=False)\n",
    "                dr_out_sithick=regrid_variable(\"sithick\",ds_sithick,ds_out,transpose=False)\n",
    "                \n",
    "                # Calculate scalar wind and organize the data arrays to be used for  given timestep (month-year)\n",
    "                wind=np.sqrt(dr_out_uas**2+dr_out_vas**2).values\n",
    "               \n",
    "                lat=dr_out_uas.lat.values\n",
    "                lon=dr_out_uas.lon.values\n",
    "                \n",
    "                clt=dr_out_clt.values\n",
    "                chl=dr_out_chl.values\n",
    "                sisnconc=dr_out_sisnconc.values\n",
    "                sisnthick=dr_out_sisnthick.values\n",
    "                siconc=dr_out_siconc.values\n",
    "                sithick=dr_out_sithick.values\n",
    "                \n",
    "                m=len(wind[:,0])\n",
    "                n=len(wind[0,:])\n",
    "                month=6\n",
    "                \n",
    "                all_direct=[]\n",
    "                all_OSA=[]\n",
    "                for hour_of_day in range(12,13,1):\n",
    "                    print(\"Running for hour {}\".format(hour_of_day))\n",
    "                 \n",
    "                    calc_radiation = [dask.delayed(radiation)(clt[j,:],lat[j,0],month,hour_of_day) for j in range(m)]\n",
    "                   \n",
    "                    # https://github.com/dask/dask/issues/5464   \n",
    "                    rad = dask.compute(calc_radiation, scheduler='processes')\n",
    "                    rads=np.asarray(rad).reshape((m, n, 3))\n",
    "                    \n",
    "                    zr = [dask.delayed(calculate_OSA)(rads[i,j,2], wind[i,j], chl[i,j], wavelengths, refractive_indexes, \n",
    "                                                    alpha_chl, alpha_w, beta_w, alpha_wc, solar_energy) \n",
    "                                  for i in range(m) \n",
    "                                  for j in range(n)]\n",
    "\n",
    "                    OSA = np.asarray(dask.compute(zr)).reshape((m, n, 2))\n",
    "                    \n",
    "                    irradiance_water = (rads[:,:,0]*OSA[:,:,0]+rads[:,:,1]*OSA[:,:,1])/(OSA[:,:,0]+OSA[:,:,1])\n",
    "                    \n",
    "                    print(\"Time to finish {} with mean OSA {}\".format(datetime.datetime.now()-startdate,\n",
    "                          np.mean(irradiance_water)))\n",
    "                    \n",
    "                    # Write to file\n",
    "                    data_array=xr.DataArray(data=irradiance_water,dims={'lat':lat,'lon':lon})\n",
    "                    if not os.path.exists(\"ncfiles\"):\n",
    "                        os.mkdir(\"ncfiles\")\n",
    "                    data_array.to_netcdf(\"ncfiles/irradiance.nc\")\n",
    "\n",
    "                    create_plots(sisnconc,sisnthick,sithick,siconc,clt,chl,rads,irradiance_water,wind,OSA,lon,lat)\n",
    "                    \n",
    "calculate_light(config_pices_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
