{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gcsfs\n",
    "#!pip install pysolar\n",
    "#!pip install zarr\n",
    "#!pip install opendrift\n",
    "#!pip install nc-time-axis\n",
    "import pprint\n",
    "import gcsfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "import cftime\n",
    "import pysolar\n",
    "from pysolar import *\n",
    "import dask\n",
    "import dask.delayed as delayed\n",
    "from dask import compute\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy\n",
    "import zarr\n",
    "\n",
    "#from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
    "import cartopy.crs as ccrs\n",
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light calculations\n",
    "Here we use pysolar python modules to perform the light calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_labels = [\"gr\"]\n",
    "\n",
    "member_ids = [\n",
    "    \"r1i1p1f1\",\n",
    "    \"r1i1p1f2\",\n",
    "    \"r1i1p1f3\",\n",
    "    \"r2i1p1f1\",\n",
    "    \"r2i1p1f2\",\n",
    "    \"r2i1p1f3\",\n",
    "    \"r3i1p1f1\",\n",
    "    \"r3i1p1f2\",\n",
    "    \"r4i1p1f1\",\n",
    "    \"r4i1p1f2\",\n",
    "    \"r4i1p1f3\",\n",
    "    \"r5i1p1f1\",\n",
    "    \"r5i1p1f2\",\n",
    "    \"r5i1p1f3\",\n",
    "    \"r6i1p1f1\",\n",
    "    \"r6i1p1f2\",\n",
    "    \"r6i1p1f3\",\n",
    "    \"r7i1p1f1\",\n",
    "    \"r7i1p1f2\",\n",
    "    \"r7i1p1f3\",\n",
    "    \"r8i1p1f1\",\n",
    "    \"r8i1p1f2\",\n",
    "    \"r8i1p1f3\",\n",
    "    \"r9i1p1f1\",\n",
    "    \"r9i1p1f2\",\n",
    "    \"r9i1p1f3\",\n",
    "    \"r102i1p1f1\",\n",
    "    \"r102i1p1f2\",\n",
    "    \"r102i1p1f3\",\n",
    "]\n",
    "member_ids = [\"r1i1p1f1\"]\n",
    "\n",
    "experiment_ids = [\"1pctCO2\"]  #'abrupt-4xCO2',\n",
    "institution_ids = [\"NOAA-GFDL\"]\n",
    "source_ids = [\"GFDL-ESM4\"]\n",
    "variable_ids = [\"sithick\", \"siconc\", \"sisnthick\", \"sisnconc\"]\n",
    "table_ids = [\"SImon\", \"SImon\", \"SImon\", \"SImon\"]\n",
    "# variable_ids = [\"sithick\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query data\n",
    "The dataset returned from the query need to be checked for time dimension. If the time array \n",
    "uses a relative date (0001 instead of 20001) then the values need to be added 2000 prior to converting to \n",
    "datetime64 format.\n",
    "\n",
    "https://unidata.github.io/cftime/api.html\n",
    "http://xarray.pydata.org/en/stable/time-series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(ds_dict, ds_area):\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for name, ds in ds_dict.items():\n",
    "\n",
    "        #  total_area = ds_area.areacella.sum(dim=['lat', 'lon'])\n",
    "        #   print(ds_area.areacella)\n",
    "        if name == \"sithick\":\n",
    "            ta_timeseries = ds.sithick.mean(\n",
    "                dim=[\"lat\", \"lon\"]\n",
    "            )  # * ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name == \"sisnthick\":\n",
    "            ta_timeseries = ds.sisnthick.mean(\n",
    "                dim=[\"lat\", \"lon\"]\n",
    "            )  # * ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name == \"siconc\":\n",
    "            ta_timeseries = ds.siconc.mean(\n",
    "                dim=[\"lat\", \"lon\"]\n",
    "            )  # * ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name == \"sisnconc\":\n",
    "            ta_timeseries = ds.sisnconc.mean(\n",
    "                dim=[\"lat\", \"lon\"]\n",
    "            )  # * ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name == \"tas\":\n",
    "            ta_timeseries = ds.tas.mean(\n",
    "                dim=[\"lat\", \"lon\"]\n",
    "            )  # * ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "\n",
    "        plt.ylabel(r\"global-mean {}\".format(name))\n",
    "        ta_timeseries.plot()\n",
    "        ta_timeseries.rolling(time=12).mean().plot(color=\"r\")\n",
    "\n",
    "        plt.xlabel(\"time\")\n",
    "        #   plt.xlim([1850,2100]);\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#  plot_map(ds)\n",
    "# plt.savefig('../figures/ssp585_global_warming.png',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(ds):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_global()\n",
    "    ds.sithick[0].plot.pcolormesh(\n",
    "        ax=ax, transform=ccrs.PlateCarree(), x=\"xc\", y=\"yc\", add_colorbar=False\n",
    "    )\n",
    "    ax.coastlines()\n",
    "    ax.set_ylim([0, 90])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_query(query_string):\n",
    "    df_sub = df.query(query_string)\n",
    "    mapper = fs.get_mapper(df_sub.zstore.values[-1])\n",
    "    ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    time_object = ds[\"time\"].values[0]\n",
    "\n",
    "    # Convert if necesssary\n",
    "    if time_object.year == 1:\n",
    "\n",
    "        times = ds[\"time\"].values\n",
    "        times_plus_2000 = []\n",
    "        for t in times:\n",
    "            times_plus_2000.append(\n",
    "                cftime.DatetimeNoLeap(t.year + 2000, t.month, t.day, t.hour)\n",
    "            )\n",
    "        ds[\"time\"].values = times_plus_2000\n",
    "        ds = xr.decode_cf(ds)\n",
    "    print(\n",
    "        \"=> Dates extracted range from {} to {}\\n\".format(\n",
    "            ds[\"time\"].values[0], ds[\"time\"].values[-1]\n",
    "        )\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_light(lon, lat, when, snow_thickness, ice_thickness):\n",
    "    altitude_deg = solar.get_altitude(lat, lon, when)\n",
    "    surface_light = radiation.get_radiation_direct(when, altitude_deg)\n",
    "\n",
    "    return calculate_light_under_sea_ice(snow_thickness, ice_thickness, surface_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateArea(lat0, lat1, lon0, lon1, areaIce):\n",
    "\n",
    "    earthRadius = 6371000\n",
    "    rad = np.pi / 180.0\n",
    "\n",
    "    \"\"\"    -180 <= lon0 < lon1 <= 180\n",
    "            -90 <= lat0 < lat1 <= 90\n",
    "            areaIce is in percent\n",
    "    \"\"\"\n",
    "\n",
    "    area = (\n",
    "        earthRadius ** 2\n",
    "        * (np.sin(lat1 * rad) - np.sin(lat0 * rad))\n",
    "        * (lon1 - lon0)\n",
    "        * rad\n",
    "    )\n",
    "    return area * (areaIce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_light_under_sea_ice(\n",
    "    snow_thickness, ice_thickness, surface_light, debug=False\n",
    "):\n",
    "    # Now calculate the amount of light below the sea ice and snow (Perovich 1996,\n",
    "    # but see  Jin 2006 Annals of Glaciology)\n",
    "    attenuationSnow = 20  # unit : m-1\n",
    "    attenuationIceTop10cm = 5\n",
    "    attenuationIceBelowSurface = 1\n",
    "    missing_value = 1e20\n",
    "\n",
    "    if 0 < snow_thickness < missing_value:\n",
    "        albedo = 0.9\n",
    "        #   if debug is True:\n",
    "        #       print(\"Albedo for snow and ice covered water: {}\".format(albedo))\n",
    "        surface_light = (1.0 - albedo) * surface_light\n",
    "    if snow_thickness == 0 and 0 < ice_thickness < missing_value:\n",
    "        albedo = 0.5\n",
    "        #    if debug is True:\n",
    "        #        print(\"Albedo for ice covered water: {}\".format(albedo))\n",
    "        surface_light = (1.0 - albedo) * surface_light\n",
    "    if (snow_thickness == 0 and ice_thickness == 0) or (\n",
    "        snow_thickness == missing_value and ice_thickness == missing_value\n",
    "    ):\n",
    "        albedo = 0.06\n",
    "        #   if debug is True:\n",
    "        #       print(\"Albedo for open water: {}\".format(albedo))\n",
    "        surface_light = (1.0 - albedo) * surface_light\n",
    "\n",
    "    Eb = surface_light\n",
    "    # if debug is True:\n",
    "    #     print(\"\\nSurface light {}\".format(Eb))\n",
    "    if 0 < snow_thickness < missing_value:\n",
    "        Eb = surface_light * np.exp(attenuationSnow * (-snow_thickness))\n",
    "    #   if debug is True:\n",
    "    #       print(\"Eb with snow (%s m) : {}\".format(snow_thickness, Eb))\n",
    "\n",
    "    if 0.1 <= ice_thickness < missing_value:\n",
    "\n",
    "        Eb = Eb * np.exp(attenuationIceTop10cm * (-0.1))\n",
    "        #     if debug is True:\n",
    "        #         print(\"Eb with ice top (%s m) : {}\".format(ice_thickness, Eb))\n",
    "        Eb = Eb * np.exp(attenuationIceBelowSurface * (-(ice_thickness - 0.1)))\n",
    "    #     if debug is True:\n",
    "    #         print(\"Eb with ice below top (%s m) : {}\".format(ice_thickness - 0.1, Eb))\n",
    "    else:\n",
    "        Eb = Eb * np.exp(attenuationIceTop10cm * (-ice_thickness))\n",
    "    #    if debug is True:\n",
    "    #        print(\"Eb with ice top (%s m) : {}\".format(ice_thickness, Eb))\n",
    "\n",
    "    # print \"Eb\", Eb, \"snow\", snowthickness, \"ice\", icethickness, \"albedo\", albedo\n",
    "\n",
    "    # if snowthickness==missing_value or icethickness==missing_value or albedo==missing_value:\n",
    "    #     return missing_value\n",
    "    return Eb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup system\n",
    "#### Setup ssh tunnel\n",
    "gcloud compute ssh  --zone=\"us-west1-b\" --ssh-flag=\"-D\" --ssh-flag=\"1080\" --ssh-flag=\"-N\" --ssh-flag=\"-n\" jupyter\n",
    " \n",
    "#### Setup Google chrome for proxy\n",
    " /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --proxy-server=\"socks5://localhost:1080\" \\\n",
    "  --host-resolver-rules=\"MAP * 0.0.0.0 , EXCLUDE localhost\" \\\n",
    "  --user-data-dir=/tmp/\n",
    "  \n",
    "#### Status\n",
    "http://jupyter:8787/status\n",
    "  \n",
    "#### Useful links\n",
    "https://climate-cms.org/2019/11/12/Calendars-and-monthly-data.html\n",
    "http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "https://rabernat.github.io/research_computing_2018/xarray-tips-and-tricks.html\n",
    "http://meteo.unican.es/work/xarray_seminar/xArray_seminar.html\n",
    " \n",
    "#### Setting up SSH port forwarding on google gloud\n",
    "https://haroldsoh.com/2016/04/28/set-up-anaconda-ipython-tensorflow-julia-on-a-google-compute-engine-vm/\n",
    " \n",
    "#### Problems memory leak\n",
    "https://github.com/dask/distributed/issues/2068\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tasks_for_dataset(dset_dict):\n",
    "\n",
    "    from dask.distributed import Client, progress\n",
    "    from numpy import vectorize\n",
    "\n",
    "    # https://github.com/dask/dask-labextension\n",
    "    client = Client(\n",
    "        \"tcp://127.0.0.1:38389\"\n",
    "    )  # , processes=False, threads_per_worker=2, n_workers=4)\n",
    "    DD_COUNT = 12\n",
    "    min_latitude = 40\n",
    "    final_year = 2101\n",
    "\n",
    "    calculate_light_under_sea_ice_vector = np.vectorize(calculate_light_under_sea_ice)\n",
    "    calculate_light_vector = np.vectorize(calculate_light)\n",
    "\n",
    "    with client:\n",
    "\n",
    "        snow_thickness = dset_dict[\"sisnthick\"].sisnthick\n",
    "        snow_thickness = snow_thickness.where(\n",
    "            snow_thickness.lat > min_latitude, drop=True\n",
    "        )\n",
    "        ice_thickness = dset_dict[\"sithick\"].sithick\n",
    "        ice_thickness = ice_thickness.where(\n",
    "            snow_thickness.lat > min_latitude, drop=True\n",
    "        )\n",
    "        times = snow_thickness[\"time\"].values\n",
    "\n",
    "        when = []\n",
    "        for ind, dd in enumerate(times):\n",
    "            date_current = datetime.datetime(\n",
    "                dd.year, dd.month, dd.day, tzinfo=datetime.timezone.utc\n",
    "            )\n",
    "            when.append(date_current)\n",
    "\n",
    "        for end_index,d in enumerate(when):\n",
    "            if d.year==final_year:\n",
    "                break\n",
    "        print('End index {} equals date {}'.format(end_index,when[end_index]))\n",
    "          \n",
    "            \n",
    "        z = np.zeros(\n",
    "            (len(when[0:end_index]), len(snow_thickness.lat.values), len(snow_thickness.lon.values))\n",
    "        )\n",
    "        lons = snow_thickness.lon.values\n",
    "        lats = snow_thickness.lat.where(\n",
    "            snow_thickness.lat > min_latitude, drop=True\n",
    "        ).values\n",
    "\n",
    "        n = len(snow_thickness.lon.values)\n",
    "        m = len(snow_thickness.lat.values)\n",
    "\n",
    "        start_time_index = 0\n",
    "        end_time_index = DD_COUNT\n",
    "        lonss, latss = np.meshgrid(lons, lats)\n",
    "              \n",
    "        for start_time_index in range(0, end_index, DD_COUNT):\n",
    "\n",
    "            ict = ice_thickness.values[start_time_index:end_time_index, :, :]\n",
    "            snt = snow_thickness.values[start_time_index:end_time_index, :, :]\n",
    "\n",
    "            zr = [\n",
    "                delayed(calculate_light_vector)(\n",
    "                    lonss, latss, when[start_time_index + t], snt[t, :, :], ict[t, :, :]\n",
    "                )\n",
    "                for t in range(DD_COUNT)\n",
    "            ]\n",
    "\n",
    "            final = dask.compute(zr)\n",
    "            zr = np.fliplr(np.array(final).reshape((DD_COUNT, m, n)))\n",
    "            z[start_time_index:end_time_index, :, :] = zr\n",
    "\n",
    "            print(\n",
    "                \"Progress indexes: start {}={} end {}={}\".format(\n",
    "                    start_time_index,\n",
    "                    when[start_time_index],\n",
    "                    end_time_index,\n",
    "                    when[end_time_index],\n",
    "                )\n",
    "            )\n",
    "            end_time_index += DD_COUNT\n",
    "\n",
    "        #  plt.figure(figsize=(12, 12))\n",
    "        #  plt.imshow(z[start_time_index, :, :])\n",
    "        #  plt.colorbar(shrink=0.3)\n",
    "        #  plt.title('Date {}'.format(when[start_time_index]))\n",
    "\n",
    "    print(\"Writing results to file. Shape of data {}\".format(np.shape(z)))\n",
    "\n",
    "    ds = xr.DataArray(\n",
    "        z, dims=[\"time\",\"lat\",\"lon\"], coords={\"lon\": lons, \"lat\": lats, \"time\": times[0:end_index]}\n",
    "    )\n",
    "    ds.to_netcdf(\"test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='esm-hist' and variable_id=='sithick'\n",
      "\n",
      "=> Dates extracted range from 1850-01-16 12:00:00 to 2014-12-16 12:00:00\n",
      "\n",
      "Running projections query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='1pctCO2' and variable_id=='sithick'\n",
      "\n",
      "=> Dates extracted range from 2001-01-16 12:00:00 to 2150-12-16 12:00:00\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='esm-hist' and variable_id=='siconc'\n",
      "\n",
      "=> Dates extracted range from 1850-01-16 12:00:00 to 2014-12-16 12:00:00\n",
      "\n",
      "Running projections query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='1pctCO2' and variable_id=='siconc'\n",
      "\n",
      "=> Dates extracted range from 2001-01-16 12:00:00 to 2150-12-16 12:00:00\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='esm-hist' and variable_id=='sisnthick'\n",
      "\n",
      "=> Dates extracted range from 1850-01-16 12:00:00 to 2014-12-16 12:00:00\n",
      "\n",
      "Running projections query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='1pctCO2' and variable_id=='sisnthick'\n",
      "\n",
      "=> Dates extracted range from 2001-01-16 12:00:00 to 2150-12-16 12:00:00\n",
      "\n",
      "Running historical query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='esm-hist' and variable_id=='sisnconc'\n",
      "\n",
      "=> Dates extracted range from 1850-01-16 12:00:00 to 2014-12-16 12:00:00\n",
      "\n",
      "Running projections query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='1pctCO2' and variable_id=='sisnconc'\n",
      "\n",
      "=> Dates extracted range from 2001-01-16 12:00:00 to 2150-12-16 12:00:00\n",
      "\n",
      "End index 3012 equals date 2101-01-16 00:00:00+00:00\n",
      "Progress indexes: start 0=1850-01-16 00:00:00+00:00 end 12=1851-01-16 00:00:00+00:00\n",
      "Progress indexes: start 12=1851-01-16 00:00:00+00:00 end 24=1852-01-16 00:00:00+00:00\n",
      "Progress indexes: start 24=1852-01-16 00:00:00+00:00 end 36=1853-01-16 00:00:00+00:00\n",
      "Progress indexes: start 36=1853-01-16 00:00:00+00:00 end 48=1854-01-16 00:00:00+00:00\n",
      "Progress indexes: start 48=1854-01-16 00:00:00+00:00 end 60=1855-01-16 00:00:00+00:00\n",
      "Progress indexes: start 60=1855-01-16 00:00:00+00:00 end 72=1856-01-16 00:00:00+00:00\n",
      "Progress indexes: start 72=1856-01-16 00:00:00+00:00 end 84=1857-01-16 00:00:00+00:00\n",
      "Progress indexes: start 84=1857-01-16 00:00:00+00:00 end 96=1858-01-16 00:00:00+00:00\n",
      "Progress indexes: start 96=1858-01-16 00:00:00+00:00 end 108=1859-01-16 00:00:00+00:00\n",
      "Progress indexes: start 108=1859-01-16 00:00:00+00:00 end 120=1860-01-16 00:00:00+00:00\n",
      "Progress indexes: start 120=1860-01-16 00:00:00+00:00 end 132=1861-01-16 00:00:00+00:00\n",
      "Progress indexes: start 132=1861-01-16 00:00:00+00:00 end 144=1862-01-16 00:00:00+00:00\n",
      "Progress indexes: start 144=1862-01-16 00:00:00+00:00 end 156=1863-01-16 00:00:00+00:00\n",
      "Progress indexes: start 156=1863-01-16 00:00:00+00:00 end 168=1864-01-16 00:00:00+00:00\n",
      "Progress indexes: start 168=1864-01-16 00:00:00+00:00 end 180=1865-01-16 00:00:00+00:00\n",
      "Progress indexes: start 180=1865-01-16 00:00:00+00:00 end 192=1866-01-16 00:00:00+00:00\n",
      "Progress indexes: start 192=1866-01-16 00:00:00+00:00 end 204=1867-01-16 00:00:00+00:00\n",
      "Progress indexes: start 204=1867-01-16 00:00:00+00:00 end 216=1868-01-16 00:00:00+00:00\n",
      "Progress indexes: start 216=1868-01-16 00:00:00+00:00 end 228=1869-01-16 00:00:00+00:00\n",
      "Progress indexes: start 252=1871-01-16 00:00:00+00:00 end 264=1872-01-16 00:00:00+00:00\n",
      "Progress indexes: start 264=1872-01-16 00:00:00+00:00 end 276=1873-01-16 00:00:00+00:00\n",
      "Progress indexes: start 276=1873-01-16 00:00:00+00:00 end 288=1874-01-16 00:00:00+00:00\n",
      "Progress indexes: start 288=1874-01-16 00:00:00+00:00 end 300=1875-01-16 00:00:00+00:00\n",
      "Progress indexes: start 300=1875-01-16 00:00:00+00:00 end 312=1876-01-16 00:00:00+00:00\n",
      "Progress indexes: start 312=1876-01-16 00:00:00+00:00 end 324=1877-01-16 00:00:00+00:00\n",
      "Progress indexes: start 324=1877-01-16 00:00:00+00:00 end 336=1878-01-16 00:00:00+00:00\n",
      "Progress indexes: start 336=1878-01-16 00:00:00+00:00 end 348=1879-01-16 00:00:00+00:00\n",
      "Progress indexes: start 348=1879-01-16 00:00:00+00:00 end 360=1880-01-16 00:00:00+00:00\n",
      "Progress indexes: start 360=1880-01-16 00:00:00+00:00 end 372=1881-01-16 00:00:00+00:00\n",
      "Progress indexes: start 372=1881-01-16 00:00:00+00:00 end 384=1882-01-16 00:00:00+00:00\n",
      "Progress indexes: start 384=1882-01-16 00:00:00+00:00 end 396=1883-01-16 00:00:00+00:00\n",
      "Progress indexes: start 396=1883-01-16 00:00:00+00:00 end 408=1884-01-16 00:00:00+00:00\n",
      "Progress indexes: start 408=1884-01-16 00:00:00+00:00 end 420=1885-01-16 00:00:00+00:00\n",
      "Progress indexes: start 420=1885-01-16 00:00:00+00:00 end 432=1886-01-16 00:00:00+00:00\n",
      "Progress indexes: start 432=1886-01-16 00:00:00+00:00 end 444=1887-01-16 00:00:00+00:00\n",
      "Progress indexes: start 444=1887-01-16 00:00:00+00:00 end 456=1888-01-16 00:00:00+00:00\n",
      "Progress indexes: start 456=1888-01-16 00:00:00+00:00 end 468=1889-01-16 00:00:00+00:00\n",
      "Progress indexes: start 468=1889-01-16 00:00:00+00:00 end 480=1890-01-16 00:00:00+00:00\n",
      "Progress indexes: start 480=1890-01-16 00:00:00+00:00 end 492=1891-01-16 00:00:00+00:00\n",
      "Progress indexes: start 492=1891-01-16 00:00:00+00:00 end 504=1892-01-16 00:00:00+00:00\n",
      "Progress indexes: start 504=1892-01-16 00:00:00+00:00 end 516=1893-01-16 00:00:00+00:00\n",
      "Progress indexes: start 516=1893-01-16 00:00:00+00:00 end 528=1894-01-16 00:00:00+00:00\n",
      "Progress indexes: start 528=1894-01-16 00:00:00+00:00 end 540=1895-01-16 00:00:00+00:00\n",
      "Progress indexes: start 540=1895-01-16 00:00:00+00:00 end 552=1896-01-16 00:00:00+00:00\n",
      "Progress indexes: start 552=1896-01-16 00:00:00+00:00 end 564=1897-01-16 00:00:00+00:00\n",
      "Progress indexes: start 564=1897-01-16 00:00:00+00:00 end 576=1898-01-16 00:00:00+00:00\n",
      "Progress indexes: start 576=1898-01-16 00:00:00+00:00 end 588=1899-01-16 00:00:00+00:00\n",
      "Progress indexes: start 588=1899-01-16 00:00:00+00:00 end 600=1900-01-16 00:00:00+00:00\n",
      "Progress indexes: start 600=1900-01-16 00:00:00+00:00 end 612=1901-01-16 00:00:00+00:00\n",
      "Progress indexes: start 612=1901-01-16 00:00:00+00:00 end 624=1902-01-16 00:00:00+00:00\n",
      "Progress indexes: start 624=1902-01-16 00:00:00+00:00 end 636=1903-01-16 00:00:00+00:00\n",
      "Progress indexes: start 636=1903-01-16 00:00:00+00:00 end 648=1904-01-16 00:00:00+00:00\n",
      "Progress indexes: start 648=1904-01-16 00:00:00+00:00 end 660=1905-01-16 00:00:00+00:00\n",
      "Progress indexes: start 660=1905-01-16 00:00:00+00:00 end 672=1906-01-16 00:00:00+00:00\n",
      "Progress indexes: start 672=1906-01-16 00:00:00+00:00 end 684=1907-01-16 00:00:00+00:00\n",
      "Progress indexes: start 684=1907-01-16 00:00:00+00:00 end 696=1908-01-16 00:00:00+00:00\n",
      "Progress indexes: start 696=1908-01-16 00:00:00+00:00 end 708=1909-01-16 00:00:00+00:00\n",
      "Progress indexes: start 708=1909-01-16 00:00:00+00:00 end 720=1910-01-16 00:00:00+00:00\n",
      "Progress indexes: start 720=1910-01-16 00:00:00+00:00 end 732=1911-01-16 00:00:00+00:00\n",
      "Progress indexes: start 732=1911-01-16 00:00:00+00:00 end 744=1912-01-16 00:00:00+00:00\n",
      "Progress indexes: start 744=1912-01-16 00:00:00+00:00 end 756=1913-01-16 00:00:00+00:00\n",
      "Progress indexes: start 756=1913-01-16 00:00:00+00:00 end 768=1914-01-16 00:00:00+00:00\n",
      "Progress indexes: start 768=1914-01-16 00:00:00+00:00 end 780=1915-01-16 00:00:00+00:00\n",
      "Progress indexes: start 780=1915-01-16 00:00:00+00:00 end 792=1916-01-16 00:00:00+00:00\n",
      "Progress indexes: start 792=1916-01-16 00:00:00+00:00 end 804=1917-01-16 00:00:00+00:00\n",
      "Progress indexes: start 804=1917-01-16 00:00:00+00:00 end 816=1918-01-16 00:00:00+00:00\n",
      "Progress indexes: start 816=1918-01-16 00:00:00+00:00 end 828=1919-01-16 00:00:00+00:00\n",
      "Progress indexes: start 828=1919-01-16 00:00:00+00:00 end 840=1920-01-16 00:00:00+00:00\n",
      "Progress indexes: start 840=1920-01-16 00:00:00+00:00 end 852=1921-01-16 00:00:00+00:00\n",
      "Progress indexes: start 852=1921-01-16 00:00:00+00:00 end 864=1922-01-16 00:00:00+00:00\n",
      "Progress indexes: start 864=1922-01-16 00:00:00+00:00 end 876=1923-01-16 00:00:00+00:00\n",
      "Progress indexes: start 876=1923-01-16 00:00:00+00:00 end 888=1924-01-16 00:00:00+00:00\n",
      "Progress indexes: start 888=1924-01-16 00:00:00+00:00 end 900=1925-01-16 00:00:00+00:00\n",
      "Progress indexes: start 900=1925-01-16 00:00:00+00:00 end 912=1926-01-16 00:00:00+00:00\n",
      "Progress indexes: start 912=1926-01-16 00:00:00+00:00 end 924=1927-01-16 00:00:00+00:00\n",
      "Progress indexes: start 924=1927-01-16 00:00:00+00:00 end 936=1928-01-16 00:00:00+00:00\n",
      "Progress indexes: start 936=1928-01-16 00:00:00+00:00 end 948=1929-01-16 00:00:00+00:00\n",
      "Progress indexes: start 948=1929-01-16 00:00:00+00:00 end 960=1930-01-16 00:00:00+00:00\n",
      "Progress indexes: start 960=1930-01-16 00:00:00+00:00 end 972=1931-01-16 00:00:00+00:00\n",
      "Progress indexes: start 972=1931-01-16 00:00:00+00:00 end 984=1932-01-16 00:00:00+00:00\n",
      "Progress indexes: start 984=1932-01-16 00:00:00+00:00 end 996=1933-01-16 00:00:00+00:00\n",
      "Progress indexes: start 996=1933-01-16 00:00:00+00:00 end 1008=1934-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1008=1934-01-16 00:00:00+00:00 end 1020=1935-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1032=1936-01-16 00:00:00+00:00 end 1044=1937-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1044=1937-01-16 00:00:00+00:00 end 1056=1938-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1056=1938-01-16 00:00:00+00:00 end 1068=1939-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1068=1939-01-16 00:00:00+00:00 end 1080=1940-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1080=1940-01-16 00:00:00+00:00 end 1092=1941-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1092=1941-01-16 00:00:00+00:00 end 1104=1942-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1104=1942-01-16 00:00:00+00:00 end 1116=1943-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1116=1943-01-16 00:00:00+00:00 end 1128=1944-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1128=1944-01-16 00:00:00+00:00 end 1140=1945-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1140=1945-01-16 00:00:00+00:00 end 1152=1946-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1152=1946-01-16 00:00:00+00:00 end 1164=1947-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1164=1947-01-16 00:00:00+00:00 end 1176=1948-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1176=1948-01-16 00:00:00+00:00 end 1188=1949-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1188=1949-01-16 00:00:00+00:00 end 1200=1950-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1200=1950-01-16 00:00:00+00:00 end 1212=1951-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1212=1951-01-16 00:00:00+00:00 end 1224=1952-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1224=1952-01-16 00:00:00+00:00 end 1236=1953-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1236=1953-01-16 00:00:00+00:00 end 1248=1954-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1248=1954-01-16 00:00:00+00:00 end 1260=1955-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1260=1955-01-16 00:00:00+00:00 end 1272=1956-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1272=1956-01-16 00:00:00+00:00 end 1284=1957-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1284=1957-01-16 00:00:00+00:00 end 1296=1958-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1296=1958-01-16 00:00:00+00:00 end 1308=1959-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1308=1959-01-16 00:00:00+00:00 end 1320=1960-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1320=1960-01-16 00:00:00+00:00 end 1332=1961-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1332=1961-01-16 00:00:00+00:00 end 1344=1962-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1344=1962-01-16 00:00:00+00:00 end 1356=1963-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1356=1963-01-16 00:00:00+00:00 end 1368=1964-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1368=1964-01-16 00:00:00+00:00 end 1380=1965-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1380=1965-01-16 00:00:00+00:00 end 1392=1966-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1392=1966-01-16 00:00:00+00:00 end 1404=1967-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1404=1967-01-16 00:00:00+00:00 end 1416=1968-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1416=1968-01-16 00:00:00+00:00 end 1428=1969-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1428=1969-01-16 00:00:00+00:00 end 1440=1970-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1440=1970-01-16 00:00:00+00:00 end 1452=1971-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1452=1971-01-16 00:00:00+00:00 end 1464=1972-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1464=1972-01-16 00:00:00+00:00 end 1476=1973-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1476=1973-01-16 00:00:00+00:00 end 1488=1974-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1488=1974-01-16 00:00:00+00:00 end 1500=1975-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1500=1975-01-16 00:00:00+00:00 end 1512=1976-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1512=1976-01-16 00:00:00+00:00 end 1524=1977-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1524=1977-01-16 00:00:00+00:00 end 1536=1978-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1536=1978-01-16 00:00:00+00:00 end 1548=1979-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1548=1979-01-16 00:00:00+00:00 end 1560=1980-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1560=1980-01-16 00:00:00+00:00 end 1572=1981-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1572=1981-01-16 00:00:00+00:00 end 1584=1982-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1584=1982-01-16 00:00:00+00:00 end 1596=1983-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1596=1983-01-16 00:00:00+00:00 end 1608=1984-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1608=1984-01-16 00:00:00+00:00 end 1620=1985-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1620=1985-01-16 00:00:00+00:00 end 1632=1986-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1632=1986-01-16 00:00:00+00:00 end 1644=1987-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1644=1987-01-16 00:00:00+00:00 end 1656=1988-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1656=1988-01-16 00:00:00+00:00 end 1668=1989-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1668=1989-01-16 00:00:00+00:00 end 1680=1990-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1680=1990-01-16 00:00:00+00:00 end 1692=1991-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1692=1991-01-16 00:00:00+00:00 end 1704=1992-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1704=1992-01-16 00:00:00+00:00 end 1716=1993-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1716=1993-01-16 00:00:00+00:00 end 1728=1994-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1728=1994-01-16 00:00:00+00:00 end 1740=1995-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1740=1995-01-16 00:00:00+00:00 end 1752=1996-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1752=1996-01-16 00:00:00+00:00 end 1764=1997-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1764=1997-01-16 00:00:00+00:00 end 1776=1998-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1776=1998-01-16 00:00:00+00:00 end 1788=1999-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1788=1999-01-16 00:00:00+00:00 end 1800=2000-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1800=2000-01-16 00:00:00+00:00 end 1812=2001-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1812=2001-01-16 00:00:00+00:00 end 1824=2002-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1824=2002-01-16 00:00:00+00:00 end 1836=2003-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1836=2003-01-16 00:00:00+00:00 end 1848=2004-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1848=2004-01-16 00:00:00+00:00 end 1860=2005-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1860=2005-01-16 00:00:00+00:00 end 1872=2006-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1872=2006-01-16 00:00:00+00:00 end 1884=2007-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1884=2007-01-16 00:00:00+00:00 end 1896=2008-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1896=2008-01-16 00:00:00+00:00 end 1908=2009-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1908=2009-01-16 00:00:00+00:00 end 1920=2010-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1920=2010-01-16 00:00:00+00:00 end 1932=2011-01-16 00:00:00+00:00\n",
      "Progress indexes: start 1932=2011-01-16 00:00:00+00:00 end 1944=2012-01-16 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Dicitionary to hold the queried variables\n",
    "dset_dict = {}\n",
    "first = True\n",
    "for experiment_id in experiment_ids:\n",
    "    for grid_label in grid_labels:\n",
    "        for source_id in source_ids:\n",
    "            for member_id in member_ids:\n",
    "                for variable_id, table_id in zip(variable_ids, table_ids):\n",
    "\n",
    "                    # Historical\n",
    "\n",
    "                    query_string = \"source_id=='{}'and table_id=='{}' and member_id=='{}' and grid_label=='{}' and experiment_id=='esm-hist' and variable_id=='{}'\".format(\n",
    "                        source_id, table_id, member_id, grid_label, variable_id\n",
    "                    )\n",
    "\n",
    "                    print(\n",
    "                        \"Running historical query on data: \\n ==> {}\\n\".format(\n",
    "                            query_string\n",
    "                        )\n",
    "                    )\n",
    "                    ds_hist = perform_query(query_string)\n",
    "\n",
    "                    # Future projection depending on choice in experiment_id\n",
    "                    query_string = \"source_id=='{}'and table_id=='{}' and member_id=='{}' and grid_label=='{}' and experiment_id=='{}' and variable_id=='{}'\".format(\n",
    "                        source_id,\n",
    "                        table_id,\n",
    "                        member_id,\n",
    "                        grid_label,\n",
    "                        experiment_id,\n",
    "                        variable_id,\n",
    "                    )\n",
    "                    print(\n",
    "                        \"Running projections query on data: \\n ==> {}\\n\".format(\n",
    "                            query_string\n",
    "                        )\n",
    "                    )\n",
    "                    ds_proj = perform_query(query_string)\n",
    "\n",
    "                    if first:\n",
    "                        df_area = df.query(\n",
    "                            \"variable_id == 'areacella' and source_id =='{}'\".format(\n",
    "                                source_id\n",
    "                            )\n",
    "                        )\n",
    "                        ds_area = xr.open_zarr(\n",
    "                            fs.get_mapper(df_area.zstore.values[0]), consolidated=True\n",
    "                        )\n",
    "                        first = False\n",
    "\n",
    "                    # Concatentate the historical and projections datasets\n",
    "                    ds = xr.concat([ds_hist, ds_proj], dim=\"time\")\n",
    "\n",
    "                    # Remove the duplicate overlapping times (e.g. 2001-2014)\n",
    "                    _, index = np.unique(ds[\"time\"], return_index=True)\n",
    "                    ds = ds.isel(time=index)\n",
    "\n",
    "                    # Save the dataset for variable_id in the dictionary\n",
    "                    dset_dict[variable_id] = ds\n",
    "\n",
    "\n",
    "run_tasks_for_dataset(dset_dict)\n",
    "\n",
    "# Plot the global average timeseries for each variable\n",
    "plot_timeseries(dset_dict, ds_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
